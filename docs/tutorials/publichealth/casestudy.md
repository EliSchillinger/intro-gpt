# Public Health Focus

## Case Studies end Examples

### Diagnostics

AI has great promise for enhancing diagnostic capabilities, but have exhibited [biases on race and ethnicity](https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html){target=_blank}. There are calls to address these biases in big data and AI for health care by taking an [open science approach](https://pmc.ncbi.nlm.nih.gov/articles/PMC8515002/){target=_blank}

* AI-enabled pulse oximeters overstate blood oxygen saturation in individuals with darker skin, [exacerbating racial bias](https://www.aclu.org/news/privacy-technology/algorithms-in-health-care-may-worsen-medical-racism){target=_blank}

* AI techniques for detecting skin cancer have lower accuracy on dark skin.


### Disease Surveillance & Prediction


### Resource Allocation

Perhaps the most ethically fraught application of AI in health care is on resource allocation. Decisions made by algorithms for high-risk care have exhibited racial biases. 

* Training data based on historical spending for health care on black vs white patients resulted in an algorithm systematically biased toward spending on more on white patients than on black patients, resulting in a perpetuation and exacerbation of the health disparity. 

### Clinical Decision Support



### Mental Health

Unmanaged AI is proving to be incredibly dangerous for the mental health of vulnerable populations. The risks and rewards of AI in the mental health space cannot be overstated. AI has been accused of contributing to individuals suicide, exacerbating distress, and cyberbullying. 

* AI therapy companies are proliferating, but [there is little oversight](https://www.apaservices.org/practice/business/technology/artificial-intelligence-chatbots-therapists), while the evidence of their scientific effectiveness is still forthcoming. 

* [Early research results](https://ai.nejm.org/doi/abs/10.1056/AIoa2400802){target=_blank} and media reports on AI-powered therapists suggest they may become valuable tools and [help mitigate provider shortages](https://www.nytimes.com/2025/04/15/health/ai-therapist-mental-health.html){target=_blank} for mental healthcare. 