# The Landscape

<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

!!! info "A Glance at the Generative AI Landscape (2024-2025)"

    The field of Generative AI is rapidly evolving. This section provides a snapshot of some of the most influential models and platforms as of early 2024, with a look towards what we might expect in 2025.

    [![tree](assets/tree.jpeg){width=800}](https://arxiv.org/abs/2304.13712){target=_blank}
    
    Image Credit: [Yang et al. :simple-arxiv:](https://arxiv.org/abs/2304.13712){target=_blank} (While this image depicts the state of LLMs in 2023, it effectively illustrates the foundational models and their evolution)

## Table: Most Popular Chat, LLM, and Multimodal Models (2024-2025)

| Name   | Creator | Application | Access | Publications  |
|------- | ------- | ------------| -------| ------------- |
| [:simple-openai: ChatGPT](https://chatgpt.com/){target=_blank}   | [:simple-openai: OpenAI](https://openai.com/chatgpt/overview/)      | Chat, Multimodal        | Free, Subscription | [:simple-openai: OpenAI Platform Documentation](https://platform.openai.com/docs/api-reference/streaming) | 
| [:simple-ollama: (o)LLaMA](https://llama.meta.com/llama3/){target=_blank}      | [:simple-meta: Meta](https://ai.meta.com/)      | LLM, Research           | Open Source   | [:simple-ollama: ollama Documentation](https://ollama.com/blog/llama3)                                                                                    |
| [:simple-googlegemini: Gemini](https://ai.google.dev/models/gemini){target=_blank} | [:simple-google: Google](https://deepmind.google/) | LLM, Multimodal, Search, Chat | Free, Subscription  | [:simple-googlegemini: Gemini Documentation](https://ai.google.dev/gemini-api/docs) |
| [:simple-google: NotebookLM](https://notebooklm.google.com/){target=_blank} | [:simple-google: Google](https://notebooklm.google/){target=_blank} | LLM, RAG, Chat | Free, Subscription | [:simple-google: Notebook LM Documentation](https://support.google.com/notebooklm?sjid=1094920587730113510-NC#topic=14287611){target=_blank} |
| [:material-microsoft: Microsoft 365 Copilot](https://copilot.microsoft.com/){target=_blank} | [:material-microsoft: Microsoft](https://www.microsoft.com/en-us/ai) | Productivity, Search, Chat | Free, Subscription | [:material-microsoft: Microsoft Copilot Documentation](https://www.microsoft.com/en-us/microsoft-365/copilot)|   |
| [:simple-x: Grok](https://x.ai/grok){target=_blank}  | [:simple-x: xAI](https://x.ai/grok){target=_blank}  | LLM, Multimodal, Chat, Computer Vision | Free, Subscription | [:simple-x: xAI Documentation](https://docs.x.ai/docs/overview) |
| [:simple-anthropic: Claude 3](https://www.anthropic.com/news/claude-3-family){target=_blank} | [:simple-anthropic: Anthropic](https://www.anthropic.com)      | Chat        | Free, Subscription  | [:simple-anthropic: Anthropic Documentation](https://docs.anthropic.com/en/docs/welcome)                                          |
| [:simple-githubcopilot: GitHub Copilot](https://github.com/features/copilot){target=_blank} | [:simple-github: GitHub](https://github.com/) | Write Code | Subscription | [:simple-githubcopilot: GitHub Copilot Documentation](https://docs.github.com/en/copilot)  |
| [:hugging: HuggingFace Chat](https://huggingface.co/chat/){target=_blank} | LLM, Multimodal, Chat | [:hugging: HuggingFace](https://huggingface.co){target=_blank} | Free, Subscription | :hugging: HuggingFace Documentation |
| [Jasper](https://www.jasper.ai/){target=_blank} | LLM, Chat | Jasper | Free, Subscription | [Jasper Documentation](https://developers.jasper.ai/docs/getting-started-1){target=_blank} |
| [Perplexity](https://www.perplexity.ai/){target=_blank} | LLM, Chat, Search Engine | Perplexity | Free, Subscription | Perplexity.ai |
| [:simple-openai: DALL·E 3](https://openai.com/dall-e-3){target=_blank}         | [:simple-openai: OpenAI](https://openai.com/)      | Computer Vision, Chat   | Via ChatGPT Plus, API       | [:simple-openai: DALL-E 3 Documentation](https://platform.openai.com/docs/guides/images)     |
| [:simple-openai: Sora](https://openai.com/sora) | [:simple-openai: OpenAI](https://openai.com/) | Computer Vision (video) | Limited access | [:simple-openai: Sora Technical Report](https://openai.com/research/video-generation-models-as-world-simulators)     |
| [Stable Diffusion 3](https://stability.ai/news/stable-diffusion-3) | [Stability AI](https://stability.ai/) | Computer Vision | Open Source, API | [:simple-arxiv: Stable Diffusion 3 Paper](https://arxiv.org/abs/2303.14686) |
| [Midjourney v6](https://www.midjourney.com/){target=_blank} | [Midjourney](https://www.midjourney.com/){target=_blank} | Computer Vision | Subscription  | [Midjourney Documentation](https://docs.midjourney.com/){target=_blank} |
| [Adobe Firefly](https://www.adobe.com/products/firefly.html){target=_blank} | [Adobe](https://www.adobe.com/){target=_blank} | Computer Vision | Proprietary, Subscription | [Adobe Documentation](https://developer.adobe.com/firefly-services/docs/guides/){target=_blank} | 


!!! Info  "About the Table"

    * **ChatGPT** is still the dominant chat platform as of late 2024, having recently released [model o1](https://openai.com/o1/){target=_blank} and announcing [model o3](https://www.youtube.com/watch?v=SKBG1sqdyIU){target=_blank}
    *   **LLaMA 3:** Meta's LLaMA 3 is a significant open-source model that is highly competitive and driving innovation.
    *   **Gemini:** Google's Gemini (formerly Bard) is rapidly evolving and positioned as a strong competitor to ChatGPT, particularly in multimodal capabilities.
    *   **Copilot:** Microsoft's Copilot (integrating OpenAI's technology) has become ubiquitous, especially for productivity and search.
    *   **Claude 3:** Anthropic's Claude 3 is gaining popularity due to its strong performance on reasoning tasks and commitment to AI safety.
    *   **Sora:** Although it is not yet fully accessible, OpenAI's text-to-video model has the potential to be a major innovation.
    *   **Grok:** is powered by _what might be_ the largest super computer in the world, xAI's Collossus 
    *   **Image Generation:** DALL-E 3, Stable Diffusion 3, and Midjourney v6 are leading the way in image generation, each with its strengths (photorealism, open-source nature, artistic style).
    *   **GitHub Copilot:** Remains a dominant force in code generation and is increasingly integrated into developers' workflows.

## View the [:octicons-trophy-24: HuggingFace :simple-huggingface: Arena LLM Leaderboard](https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard){target=_blank}

<iframe
	src="https://lmarena-ai-chatbot-arena-leaderboard.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

## Table: Prices of Services (last checked 12/2024)

| **LLM Service**  | **Plan** | **Price (per month)** | **Details**  |
| :--------------- | :------- | :-------------------- | :----------- |
| [**ChatGPT**](https://chat.openai.com/auth/login){target=_blank} | Free | $0 | Access to GPT-3.5 model. Limited availability during peak times. |
| | Plus | $20   | Access to o1, GPT-4, priority access, faster responses. 50 msgs/3hrs on GPT-4, more on GPT-3.5 |
| | Pro | $200 | Access to o1, GPT-4, higher priority  access, faster responses. | |
| [**ChatGPT Enterprise**](https://openai.com/enterprise){target=_blank} | Enterprise | Contact Sales  | Enhanced security, privacy, admin controls, and higher usage limits. Minimum 150 users |
| [**OpenAI Platform API**](https://platform.openai.com/signup){target=_blank} | Pay-As-You-Go | Varies | **o1:** $15.00/1M input tokens <br> **GPT-4 Turbo:** $0.01/1K input tokens, $0.03/1K output tokens. <br> **GPT-4:** $0.03/1K input, $0.06/1K output (8K context), $0.06/1k input, $0.12/1K output (32K) <br> **GPT-3.5 Turbo:** $0.0005/1K input, $0.0015/1K output |
| [**Google Gemini**](https://gemini.google.com/){target=_blank} | Free | Free | Access to Gemini Pro. Limited availability. |
| | Google One AI Premium | $19.99  | Access to Gemini Advanced, 2TB storage, and other Google One benefits. |
| | Gemini Education | $18 | Access to Gemini Advanced |
| | Gemini Education Plus | $27 | Access to Gemini Advanced | 
| | Notebook LM | Part of Gemini subscription | Access to Gemini Advanced |
| [**Vertex AI Gemini API**](https://cloud.google.com/vertex-ai/docs/generative-ai/pricing){target=_blank} | Pay-As-You-Go | Varies | **Gemini 1.0 Pro:** $0.00025/1K input characters, $0.0005/1K output characters, $0.002/image input. <br> **Gemini 1.5 Pro:** $0.00125/1K input characters, $0.00375/1K output characters. |
| [**Grok by xAI**](https://grok.x.ai/){target=_blank} | Basic (Via X Premium)| $8 | Access to Grok via X Premium subscription, also includes ad-free access to X.|
| | Premium+ (Via X Premium+) | $16 | Includes all Basic features, plus largest reply boost and access to full suite of X Premium tools. |
| [**Midjourney**](https://www.midjourney.com/account/){target=_blank} | Basic | $10 | ~200 image generations/month (3.3 hrs fast GPU time). |
| | Standard | $30 | 15 hrs fast GPU time/month, unlimited relaxed GPU time. |
| | Pro | $60 | 30 hrs fast GPU time/month, unlimited relaxed GPU time, stealth mode. |
| | Mega | $120 | 60 hrs fast GPU time/month, unlimited relaxed GPU time, stealth mode. |
| [**DALL·E 3**](https://openai.com/dall-e-3){target=_blank} | Via ChatGPT Plus  | Included in ChatGPT Plus   | Available for image generation within ChatGPT Plus.  |
| [**DALL-E API**](https://openai.com/dall-e-3){target=_blank} | Pay-as-you-go | Varies | **DALL-E 3:** Standard quality $0.040/image, HD quality $0.080/image. <br> **DALL-E 2:** $0.020/image (1024x1024), $0.018/image (512x512), $0.016/image (256x256). |
| [**OpenAI Sora**](https://sora.com/onboarding)){target=_blank} | Research Preview | Not yet released |  Not yet available to the public. Currently in a red teaming phase. |
| [**Anthropic Claude**](https://www.anthropic.com/pricing){target=_blank} | Claude 3 Haiku | $0.25/1K input, $1.25/1K output | Entry-level model with 200K context window. |
| | Claude 3 Sonnet | $3/1K input, $15/1K output  | Mid-tier model with enhanced capabilities, 200K context window. |
| | Claude 3 Opus | $15/1K input, $75/1K output | Advanced model comparable to GPT-4, 200K context window. |
| [**Mistral AI**](https://mistral.ai/technology/#pricing){target=_blank} | Mistral Small | $2/1M input, $6/1M output | Suitable for lightweight tasks. |
|  | Mistral Medium | $2.7/1M input, $8.1/1M output | Balanced performance for general use. |
| | Mistral Large | $8/1M input, $24/1M output | High-performance model for complex tasks. |
| [**Microsoft Copilot**](https://copilot.microsoft.com/){target=_blank} | Free | Free | Access to basic Copilot features, web grounding, GPT-4, and DALL-E 3 |
| | Pro | $20/user | Priority access to GPT-4 and GPT-4 Turbo, faster performance, 100 boosts/day with DALL-E 3 |
| [**Microsoft 365 Copilot**](https://www.microsoft.com/en-us/microsoft-365/business/compare-all-microsoft-365-business-products-b){target=_blank} | Add-on | $30/user | AI-powered assistance integrated with Microsoft 365 apps. Requires a Microsoft 365 Business Standard, Business Premium, E3, or E5 license. |
| [**GitHub Copilot**](https://github.com/features/copilot){target=_blank} | Individual | $10 | AI coding assistant for developers. |
| | Business | $19/user | Includes team-based collaboration features. |
| | Enterprise | $39/user | Includes organization-wide policy management and enhanced security features. |
| [**Ollama**](https://ollama.com/download){target=_blank} | Local Install | Free | Run large language models locally. Requires a compatible GPU and technical setup. |
| [**Meta Llama 3**](https://llama.meta.com/llama3/){target=_blank} | Open Source | Free | Open-source foundation models for research and commercial use. Requires technical setup for local hosting. |
| [**Replit Ghostwriter**](https://replit.com/pricing){target=_blank} | Included in Replit Core | $20 | AI assistant for coding and debugging, integrated into the Replit IDE. Includes all other Replit Core features. |
| [**Jasper AI**](https://www.jasper.ai/pricing){target=_blank} | Creator | $49 | Writing assistant with templates and AI tools for individuals.|
| | Teams | $125 | Advanced writing, commands, and longer outputs for small teams.| | Business | Contact Sales | Custom pricing for larger organizations with advanced needs. |
| [**Character AI**](https://beta.character.ai/){target=_blank} | c.ai+ | $9.99 | Conversational AI for entertainment and character interactions. Plus features include priority access, faster responses, and early access to new features. |
| [**Perplexity AI**](https://www.perplexity.ai/){target=_blank} | Pro  | $20  | AI-powered search assistant with enhanced query capabilities, unlimited file uploads, and access to various models.                                  |
| [**Amazon Bedrock**](https://aws.amazon.com/bedrock/pricing/){target=_blank} | On-Demand | Varies | Pay-as-you-go pricing for various foundation models, including those from Anthropic, Cohere, Meta, Mistral AI, and Amazon. |
| [**Azure AI Foundry**](https://ai.azure.com/){target=_blank} | On-Demand | Varies | Pay-as-you-go pricing for various foundation models, including those from Anthropic, Meta, Mistral AI, and OpenAI |
| [**Google Vertex AI**](https://cloud.google.com/vertex-ai){target=_blank} | On-Demand | Varies | Pay-as-you-go pricing for various foundation models, powered by Gemini with 160+ other foundation models |
| [**You.com**](https://you.com/pro){target=_blank} | YouPro | $20 | Access to latest AI models, personalized AI with memory, advanced AI writing tools. |
| [**Poe by Quora**](https://poe.com/){target=_blank} | Monthly | $19.99 | Access to various chatbots, including GPT-4, Claude, and others. Limited messages on some models. |
|                                                        | Yearly | $199.99 | Annual subscription with access to all chatbots. Limited messages on some models. |
| [**Continue.dev**](https://continue.dev/) | Open Source | Free | Open-source autopilot for software development. VS Code and JetBrains extension. Integrates with any LLM. |

**Notes:**

*   Token pricing for API access can be complex. Refer to each provider's pricing page for the most accurate and up-to-date details.
*   "Contact Sales" typically indicates that pricing is customized based on usage, features, and the specific needs of the customer.
*   Many services offer free trials or limited free tiers, allowing you to test them out before committing to a paid plan.

**Additional Chatbot and LLM Services:**

1.  **Amazon Bedrock, Azure AI Foundry, Google Vertex:** Provide access to various foundation models but each run on a respective cloud service provider's hardware. Ideal for companies and institutions already running their infrastructure on commercial cloud services. 
   
2.  **You.com:** Offers a pro plan with access to latest AI models, personalized AI with memory and advanced AI writing tools.
   
3.  **Poe by Quora:**  A platform that gives you access to various chatbots (like GPT-4, Claude, etc.) through a single subscription.

!!! Info "Stable Diffusion Image and Video"

    **Stable Diffusion 3**

    [Stable Diffusion 3](https://stability.ai/stable-diffusion-3){target=_blank} is the latest iteration of the popular open-source text-to-image model developed by [Stability AI](https://stability.ai/){target=_blank}. It builds upon the advancements of previous versions, offering improved image quality, more accurate adherence to prompts, and enhanced capabilities for generating complex scenes and details.

    Stable Diffusion models are available via [HuggingFace](https://huggingface.co/stabilityai){target=_blank}, [GitHub](https://github.com/Stability-AI/StableDiffusion3){target=_blank} and through various APIs and user interfaces.

    Diffusion models have two modes, forward and reverse. Forward diffusion adds random noise until the image is lost. Reverse diffusion uses Markov Chains to recover data from a Gaussian distribution, thereby gradually removing noise.

    Stable Diffusion relies upon [Latent Diffusion Model (LDM) :simple-arxiv:](https://arxiv.org/abs/2112.10752){target=_blank}

    **Other Notable Image Generation Models**

    *   [DALL·E 3](https://openai.com/dall-e-3){target=_blank} (OpenAI) is known for its photorealistic image generation and ability to understand complex prompts. It's integrated into ChatGPT Plus and available through an API.
    *   [Midjourney v6](https://www.midjourney.com/){target=_blank} is highly regarded for its artistic and stylized image generation. It's accessible through a Discord interface and requires a subscription.
    *   [Imagen 2](https://deepmind.google/technologies/imagen-2/){target=_blank} (Google): Not directly accessible to the public, but notable for its photorealistic text-to-image generation capabilities.
    *   [Adobe Firefly](https://www.adobe.com/products/firefly.html){target=_blank} is integrated into the Adobe Creative Cloud suite of applications and is geared toward enterprise creative workflows.

    **Video Generation Models**

    *   [Sora](https://openai.com/sora){target=_blank} (OpenAI) has generated significant excitement for its ability to create realistic and imaginative videos from text prompts. It is currently available on a limited basis.
    *   [Runway Gen-2](https://runwayml.com/){target=_blank} allows for text-to-video, image-to-video, and video-to-video editing. It's popular among video creators for its accessibility and range of features.
    *   [Pika Labs](https://www.pika.art/){target=_blank} is an additional option that allows for text-to-video generation and editing.
    *   [Stable Video Diffusion](https://stability.ai/news/introducing-stable-video-diffusion-generating-videos-from-images-with-svd-and-svd-xt){target=_blank} is an image-to-video diffusion model that allows users to generate short video clips based on a still image input.

    **Image and Video Segmentation**

    [Segment Anything (Meta)](https://segment-anything.com/){target=_blank}, [Kirillov et al. :simple-arxiv:](https://doi.org/10.48550/arXiv.2304.02643){target=_blank}, is a powerful image segmentation technology that allows you to isolate objects within images with high precision.

    **Emerging Trends in Image and Video Analysis**

    *   **Multimodal Integration:** Combining image/video analysis with other modalities (text, audio) for a more holistic understanding of content.
    *   **3D Scene Generation:**  Generating 3D models and environments from images and videos.
    *   **Real-time Analysis:**  Performing image and video analysis in real-time for applications like augmented reality and live video processing.

??? Info "Understanding Embeddings"

    [What are Embeddings? - Vicki Boykis](https://vickiboykis.com/what_are_embeddings/){target=_blank} - [download PDF :fontawesome-regular-file-pdf:](https://raw.githubusercontent.com/veekaybee/what_are_embeddings/main/embeddings.pdf)
    
    Embeddings are a way to represent data (words, images, etc.) as numerical vectors in a multi-dimensional space. These vectors capture semantic relationships between data points, meaning similar items are located closer together in the embedding space.

    Embedded space for geospatial applications:
    
    <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Visualizing how embeddings can organize satellite imagery. Millions of points covering the state of Alabama move between their geographic position and their location in the embedding space. <a href="https://t.co/Z6FtoMQ84B">pic.twitter.com/Z6FtoMQ84B</a></p>&mdash; Caleb Kruse (@clkruse) <a href="https://twitter.com/clkruse/status/1658131846121803777?ref_src=twsrc%5Etfw">May 15, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

    Embedded space for natural language:

    [Credit: Stephen Wolfram](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/){target=_blank}

    [![wolfram](https://content.wolfram.com/uploads/sites/43/2023/02/hero3-chat-exposition.png)](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)

    **Why are Embeddings Important?**

    *   **Machine Learning:** Embeddings are essential for training machine learning models, as they provide a way to represent complex data in a format that algorithms can understand.
    *   **Semantic Search:**  Embeddings enable semantic search, where you can find information based on meaning rather than just keyword matching.
    *   **Recommendation Systems:** Embeddings help power recommendation systems by identifying items with similar characteristics.
    *   **Data Visualization:**  Embeddings can be used to visualize relationships between data points in a lower-dimensional space.

!!! Info "Glossary"

    [:simple-google: Google's Machine Learning Glossary](https://developers.google.com/machine-learning/glossary){target=_blank}

    [:simple-nvidia: NVIDIA's Data Science Glossary](https://www.nvidia.com/en-us/glossary){target=_blank}

    **Agentic AI:** uses sophisticated reasoning and iterative planning to autonomously solve complex, multi-step problems.

    **Anthropic:**  
    A research organization emphasizing AI safety and governance. Known for **Claude**, a large language model (LLM) with advanced reasoning and robust safety features.

    **ChatGPT:**  
    OpenAI’s general-purpose LLM, renowned for its conversational strengths, versatility, and ability to adapt to varied tasks through effective prompt engineering.

    **Claude:**  
    Anthropic’s LLM, recognized for its interpretability, strong reasoning capabilities, and rigorous safety considerations.

    **Copilot (GitHub, Microsoft):**  
    An AI-driven developer assistant offering code suggestions, debugging support, and efficiency improvements, leveraging generative AI to boost productivity.

    **Embeddings:**  
    Numerical vector representations of data (e.g., text, images, audio) that capture semantic meaning and relationships. Useful for search, clustering, recommendation, and more.

    **Foundation Models:**  
    Large-scale deep learning models (e.g., LLMs, vision models, multimodal models) trained on massive datasets. They serve as a base or "foundation" for a wide range of downstream tasks, enabling transfer learning and rapid adaptation.

    **Gemini:**  
    Google’s family of multimodal foundation models, capable of understanding and generating text, images, and other data types, reflecting Google’s advancements in AI research.

    **GitHub:**  
    A leading platform for version control and software collaboration. Now integrated with AI tools like GitHub Copilot for enhanced code development workflows.

    **HuggingFace:**  
    A hub and community for open-source AI models, datasets, and applications. Widely used in the natural language processing (NLP) community for model sharing and development.

    **Large Language Models (LLMs):**  
    A subset of foundation models trained on extensive text corpora, enabling them to generate human-like text, summarize information, reason about topics, and perform a variety of NLP tasks. Examples include **GPT**, **Claude**, and **Gemini**.

    **Parameters:**  
    The trainable values within a neural network, updated during the training process to minimize loss and define the model’s learned behavior.

    **Prompt Engineering:**  
    The practice of crafting, refining, and optimizing instructions (prompts) given to AI models in order to guide their outputs toward desired results.

    **Stable Diffusion:**  
    A family of open-source latent-diffusion-based models used for generating high-quality images from text or other forms of input (e.g., sketches).

    **Token:**  
    A fundamental unit of text—often a word, subword, or character—that LLMs process when understanding or generating language.

    **Weights:**  
    Numerical parameters within a neural network that determine the strength of connections between neurons or nodes.

    **Zero-shot Learning:**  
    The capability of an AI model to perform tasks it has never been explicitly trained on, often made possible by large-scale pretraining on diverse datasets.
